{"id": "2602.22265", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.22265", "abs": "https://arxiv.org/abs/2602.22265", "authors": ["Chika Maduabuchi"], "title": "Entropy-Controlled Flow Matching", "comment": null, "summary": "Modern vision generators transport a base distribution to data through time-indexed measures, implemented as deterministic flows (ODEs) or stochastic diffusions (SDEs). Despite strong empirical performance, standard flow-matching objectives do not directly control the information geometry of the trajectory, allowing low-entropy bottlenecks that can transiently deplete semantic modes. We propose Entropy-Controlled Flow Matching (ECFM): a constrained variational principle over continuity-equation paths enforcing a global entropy-rate budget d/dt H(mu_t) >= -lambda. ECFM is a convex optimization in Wasserstein space with a KKT/Pontryagin system, and admits a stochastic-control representation equivalent to a Schrodinger bridge with an explicit entropy multiplier. In the pure transport regime, ECFM recovers entropic OT geodesics and Gamma-converges to classical OT as lambda -> 0. We further obtain certificate-style mode-coverage and density-floor guarantees with Lipschitz stability, and construct near-optimal collapse counterexamples for unconstrained flow matching.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.22267", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.22267", "abs": "https://arxiv.org/abs/2602.22267", "authors": ["Osimone Imhogiemhe", "Yoann Jus", "Hubert Lejeune", "Sa\u00efd Moussaoui"], "title": "Data-Driven Supervision of a Thermal-Hydraulic Process Towards a Physics-Based Digital Twin", "comment": null, "summary": "The real-time supervision of production processes is a common challenge across several industries. It targets process component monitoring and its predictive maintenance in order to ensure safety, uninterrupted production and maintain high efficiency level. The rise of advanced tools for the simulation of physical systems in addition to data-driven machine learning models offers the possibility to design numerical tools dedicated to efficient system monitoring. In that respect, the digital twin concept presents an adequate framework that proffers solution to these challenges. The main purpose of this paper is to develop such a digital twin dedicated to fault detection and diagnosis in the context of a thermal-hydraulic process supervision. Based on a numerical simulation of the system, in addition to machine learning methods, we propose different modules dedicated to process parameter change detection and their on-line estimation. The proposed fault detection and diagnosis algorithm is validated on a specific test scenario, with single one-off parameter change occurrences in the system. The numerical results show good accuracy in terms of parameter variation localization and the update of their values.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f00\u53d1\u4e86\u57fa\u4e8e\u6570\u5b57\u5b6a\u4f53\u6846\u67b6\u7684\u6545\u969c\u68c0\u6d4b\u4e0e\u8bca\u65ad\u7b97\u6cd5\uff0c\u7ed3\u5408\u6570\u503c\u4eff\u771f\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u70ed\u5de5\u6c34\u529b\u8fc7\u7a0b\u76d1\u63a7\u4e2d\u7684\u53c2\u6570\u53d8\u5316\u68c0\u6d4b\u4e0e\u5728\u7ebf\u4f30\u8ba1\u3002", "motivation": "\u5de5\u4e1a\u751f\u4ea7\u8fc7\u7a0b\u5b9e\u65f6\u76d1\u63a7\u662f\u591a\u4e2a\u884c\u4e1a\u9762\u4e34\u7684\u5171\u540c\u6311\u6218\uff0c\u9700\u8981\u5bf9\u8fc7\u7a0b\u7ec4\u4ef6\u8fdb\u884c\u76d1\u63a7\u548c\u9884\u6d4b\u6027\u7ef4\u62a4\uff0c\u4ee5\u786e\u4fdd\u5b89\u5168\u3001\u6301\u7eed\u751f\u4ea7\u5e76\u4fdd\u6301\u9ad8\u6548\u7387\u3002\u6570\u5b57\u5b6a\u4f53\u6982\u5ff5\u4e3a\u8bbe\u8ba1\u9ad8\u6548\u7684\u7cfb\u7edf\u76d1\u63a7\u6570\u503c\u5de5\u5177\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "method": "\u57fa\u4e8e\u70ed\u5de5\u6c34\u529b\u8fc7\u7a0b\u7684\u6570\u503c\u4eff\u771f\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u7528\u4e8e\u8fc7\u7a0b\u53c2\u6570\u53d8\u5316\u68c0\u6d4b\u548c\u5728\u7ebf\u4f30\u8ba1\u7684\u4e0d\u540c\u6a21\u5757\u3002\u5f00\u53d1\u4e86\u4e13\u95e8\u7684\u6545\u969c\u68c0\u6d4b\u4e0e\u8bca\u65ad\u7b97\u6cd5\uff0c\u5e76\u5728\u7279\u5b9a\u6d4b\u8bd5\u573a\u666f\u4e0b\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "\u5728\u5355\u4e00\u53c2\u6570\u53d8\u5316\u7684\u6d4b\u8bd5\u573a\u666f\u4e2d\uff0c\u7b97\u6cd5\u5728\u53c2\u6570\u53d8\u5316\u5b9a\u4f4d\u548c\u6570\u503c\u66f4\u65b0\u65b9\u9762\u8868\u73b0\u51fa\u826f\u597d\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u6570\u5b57\u5b6a\u4f53\u6846\u67b6\u4e3a\u5de5\u4e1a\u8fc7\u7a0b\u76d1\u63a7\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6240\u63d0\u51fa\u7684\u6545\u969c\u68c0\u6d4b\u4e0e\u8bca\u65ad\u7b97\u6cd5\u80fd\u591f\u51c6\u786e\u68c0\u6d4b\u548c\u5b9a\u4f4d\u7cfb\u7edf\u53c2\u6570\u53d8\u5316\uff0c\u9a8c\u8bc1\u4e86\u6570\u5b57\u5b6a\u4f53\u5728\u8fc7\u7a0b\u76d1\u63a7\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2602.22268", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.22268", "abs": "https://arxiv.org/abs/2602.22268", "authors": ["Changhai Zhou", "Shiyang Zhang", "Yuhua Zhou", "Qian Qiao", "Jun Gao", "Cheng Jin", "Kaizhou Qin", "Weizhong Zhang"], "title": "AutoQRA: Joint Optimization of Mixed-Precision Quantization and Low-rank Adapters for Efficient LLM Fine-Tuning", "comment": "15 pages, 10 figures", "summary": "Quantization followed by parameter-efficient fine-tuning has emerged as a promising paradigm for downstream adaptation under tight GPU memory constraints. However, this sequential pipeline fails to leverage the intricate interaction between quantization bit-width and LoRA rank. Specifically, a carefully optimized quantization allocation with low quantization error does not always translate to strong fine-tuning performance, and different bit-width and rank configurations can lead to significantly varying outcomes under the same memory budget. To address this limitation, we propose AutoQRA, a joint optimization framework that simultaneously optimizes the bit-width and LoRA rank configuration for each layer during the mixed quantized fine-tuning process. To tackle the challenges posed by the large discrete search space and the high evaluation cost associated with frequent fine-tuning iterations, AutoQRA decomposes the optimization process into two stages. First, it first conducts a global multi-fidelity evolutionary search, where the initial population is warm-started by injecting layer-wise importance priors. This stage employs specific operators and a performance model to efficiently screen candidate configurations. Second, trust-region Bayesian optimization is applied to locally refine promising regions of the search space and identify optimal configurations under the given memory budget. This approach enables active compensation for quantization noise in specific layers during training. Experiments show that AutoQRA achieves performance close to full-precision fine-tuning with a memory footprint comparable to uniform 4-bit methods.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.22269", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.22269", "abs": "https://arxiv.org/abs/2602.22269", "authors": ["Arnab Nath", "Harsh Kasyap"], "title": "CQSA: Byzantine-robust Clustered Quantum Secure Aggregation in Federated Learning", "comment": "6 pages, 3 figures", "summary": "Federated Learning (FL) enables collaborative model training without sharing raw data. However, shared local model updates remain vulnerable to inference and poisoning attacks. Secure aggregation schemes have been proposed to mitigate these attacks. In this work, we aim to understand how these techniques are implemented in quantum-assisted FL. Quantum Secure Aggregation (QSA) has been proposed, offering information-theoretic privacy by encoding client updates into the global phase of multipartite entangled states. Existing QSA protocols, however, rely on a single global Greenberger-Horne-Zeilinger (GHZ) state shared among all participating clients. This design poses fundamental challenges: fidelity of large-scale GHZ states deteriorates rapidly with the increasing number of clients; and (ii) the global aggregation prevents the detection of Byzantine clients. We propose Clustered Quantum Secure Aggregation (CQSA), a modular aggregation framework that reconciles the physical constraints of near-term quantum hardware along with the need for Byzantine-robustness in FL. CQSA randomly partitions the clients into small clusters, each performing local quantum aggregation using high-fidelity, low-qubit GHZ states. The server analyzes statistical relationships between cluster-level aggregates employing common statistical measures such as cosine similarity and Euclidean distance to identify malicious contributions. Through theoretical analysis and simulations under depolarizing noise, we demonstrate that CQSA ensures stable model convergence, achieves superior state fidelity over global QSA.", "AI": {"tldr": "\u63d0\u51fa\u4e86Clustered Quantum Secure Aggregation\uff08CQSA\uff09\u2014\u2014\u4e00\u79cd\u6a21\u5757\u5316\u91cf\u5b50\u5b89\u5168\u805a\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5ba2\u6237\u5206\u6210\u5c0f\u96c6\u7fa4\u4f7f\u7528\u9ad8\u4fdd\u771f\u5ea6\u7684\u4f4e\u91cf\u5b50\u6bd4\u7279GHZ\u6001\u8fdb\u884c\u672c\u5730\u91cf\u5b50\u805a\u5408\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5168\u5c40\u91cf\u5b50\u5b89\u5168\u805a\u5408\u65b9\u6848\u5728\u5927\u89c4\u6a21\u90e8\u7f72\u65f6\u7684\u4fdd\u771f\u5ea6\u4e0b\u964d\u548c\u62dc\u5360\u5ead\u5ba2\u6237\u7aef\u68c0\u6d4b\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u91cf\u5b50\u5b89\u5168\u805a\u5408\u534f\u8bae\u4f9d\u8d56\u4e8e\u6240\u6709\u53c2\u4e0e\u5ba2\u6237\u5171\u4eab\u7684\u5355\u4e2a\u5168\u5c40GHZ\u6001\uff0c\u8fd9\u5b58\u5728\u4e24\u4e2a\u57fa\u672c\u6311\u6218\uff1a\u968f\u7740\u5ba2\u6237\u6570\u91cf\u7684\u589e\u52a0\uff0c\u5927\u89c4\u6a21GHZ\u6001\u7684\u4fdd\u771f\u5ea6\u8fc5\u901f\u4e0b\u964d\uff1b\u5168\u5c40\u805a\u5408\u9632\u6b62\u4e86\u62dc\u5360\u5ead\u5ba2\u6237\u7aef\u7684\u68c0\u6d4b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u534f\u8c03\u8fd1\u671f\u91cf\u5b50\u786c\u4ef6\u7684\u7269\u7406\u7ea6\u675f\u4e0e\u8054\u90a6\u5b66\u4e60\u4e2d\u5bf9\u62dc\u5360\u5ead\u9c81\u68d2\u6027\u9700\u6c42\u7684\u65b0\u65b9\u6848\u3002", "method": "\u63d0\u51faCQSA\u6846\u67b6\uff1a1. \u5c06\u5ba2\u6237\u968f\u673a\u5206\u6210\u5c0f\u96c6\u7fa4\uff1b2. \u6bcf\u4e2a\u96c6\u7fa4\u4f7f\u7528\u9ad8\u4fdd\u771f\u5ea6\u3001\u4f4e\u91cf\u5b50\u6bd4\u7279\u7684GHZ\u6001\u8fdb\u884c\u672c\u5730\u91cf\u5b50\u805a\u5408\uff1b3. \u670d\u52a1\u5668\u5206\u6790\u96c6\u7fa4\u7ea7\u805a\u5408\u4e4b\u95f4\u7684\u7edf\u8ba1\u5173\u7cfb\uff08\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u548c\u6b27\u6c0f\u8ddd\u79bb\u7b49\u7edf\u8ba1\u5ea6\u91cf\uff09\u6765\u8bc6\u522b\u6076\u610f\u8d21\u732e\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u53bb\u6781\u5316\u566a\u58f0\u4e0b\u7684\u6a21\u62df\u8868\u660e\uff0cCQSA\u786e\u4fdd\u4e86\u7a33\u5b9a\u7684\u6a21\u578b\u6536\u655b\uff0c\u5e76\u5728\u72b6\u6001\u4fdd\u771f\u5ea6\u4e0a\u4f18\u4e8e\u5168\u5c40QSA\u3002", "conclusion": "CQSA\u6210\u529f\u5730\u534f\u8c03\u4e86\u8fd1\u671f\u91cf\u5b50\u786c\u4ef6\u7684\u7269\u7406\u7ea6\u675f\u4e0e\u8054\u90a6\u5b66\u4e60\u4e2d\u5bf9\u4e8e\u62dc\u5360\u5ead\u9c81\u68d2\u6027\u7684\u9700\u6c42\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u91cf\u5b50\u8f85\u52a9\u8054\u90a6\u5b66\u4e60\u5b89\u5168\u805a\u5408\u65b9\u6848\u3002"}}
{"id": "2602.22271", "categories": ["cs.LG", "math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.22271", "abs": "https://arxiv.org/abs/2602.22271", "authors": ["Deepak Agarwal", "Dhyey Dharmendrakumar Mavani", "Suyash Gupta", "Karthik Sethuraman", "Tejas Dharamsi"], "title": "Support Tokens, Stability Margins, and a New Foundation for Robust LLMs", "comment": "39 pages, 6 figures", "summary": "Self-attention is usually described as a flexible, content-adaptive way to mix a token with information from its past. We re-interpret causal self-attention transformers, the backbone of modern foundation models, within a probabilistic framework, much like how classical PCA is extended to probabilistic PCA. However, this re-formulation reveals a surprising and deeper structural insight: due to a change-of-variables phenomenon, a barrier constraint emerges on the self-attention parameters. This induces a highly structured geometry on the token space, providing theoretical insights into the dynamics of LLM decoding. This reveals a boundary where attention becomes ill-conditioned, leading to a margin interpretation similar to classical support vector machines. Just like support vectors, this naturally gives rise to the concept of support tokens.\n  Furthermore, we show that LLMs can be interpreted as a stochastic process over the power set of the token space, providing a rigorous probabilistic framework for sequence modeling. We propose a Bayesian framework and derive a MAP estimation objective that requires only a minimal modification to standard LLM training: the addition of a smooth log-barrier penalty to the usual cross-entropy loss. We demonstrate that this provides more robust models without sacrificing out-of-sample accuracy and that it is straightforward to incorporate in practice.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u56e0\u679c\u81ea\u6ce8\u610f\u529btransformer\u91cd\u65b0\u89e3\u91ca\u4e3a\u6982\u7387\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u81ea\u6ce8\u610f\u529b\u53c2\u6570\u5b58\u5728\u5c4f\u969c\u7ea6\u675f\uff0c\u8fd9\u8bf1\u5bfc\u4e86token\u7a7a\u95f4\u7684\u9ad8\u5ea6\u7ed3\u6784\u5316\u51e0\u4f55\u5f62\u72b6\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u652f\u6301\u5411\u91cf\u673a\u539f\u7406\u7684'\u652f\u6301token'\u6982\u5ff5\u3002\u7814\u7a76\u8fd8\u5c55\u793a\u4e86LLM\u53ef\u88ab\u89e3\u91ca\u4e3atoken\u7a7a\u95f4\u5e42\u96c6\u4e0a\u7684\u968f\u673a\u8fc7\u7a0b\uff0c\u63d0\u51fa\u4e86\u8d1d\u53f6\u65af\u6846\u67b6\u548cMAP\u4f30\u8ba1\u76ee\u6807\uff0c\u53ea\u9700\u5728\u6807\u51c6LLM\u8bad\u7ec3\u4e2d\u6dfb\u52a0\u5e73\u6ed1\u5bf9\u6570\u5c4f\u969c\u60e9\u7f5a\u5373\u53ef\u5b9e\u73b0\u66f4\u7a33\u5065\u7684\u6a21\u578b\u3002", "motivation": "\u52a8\u673a\u662f\u91cd\u65b0\u89e3\u91ca\u73b0\u4ee3\u57fa\u7840\u6a21\u578b\u7684\u6838\u5fc3\u7ec4\u4ef6\u2014\u2014\u56e0\u679c\u81ea\u6ce8\u610f\u529btransformer\uff0c\u5c06\u5176\u7f6e\u4e8e\u7c7b\u4f3c\u6982\u7387PCA\u7684\u6846\u67b6\u4e2d\uff0c\u4ee5\u63ed\u793a\u5176\u5e95\u5c42\u7ed3\u6784\u548c\u7406\u8bba\u6d1e\u5bdf\u3002\u8fd9\u79cd\u91cd\u65b0\u8868\u8ff0\u65e8\u5728\u63d0\u4f9b\u5bf9LLM\u89e3\u7801\u52a8\u529b\u5b66\u66f4\u6df1\u5165\u7684\u7406\u89e3\uff0c\u5e76\u5efa\u7acb\u66f4\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1) \u5c06\u56e0\u679c\u81ea\u6ce8\u610f\u529b\u91cd\u65b0\u89e3\u91ca\u4e3a\u6982\u7387\u6846\u67b6\uff1b2) \u63ed\u793a\u81ea\u6ce8\u610f\u529b\u53c2\u6570\u4e2d\u7684\u5c4f\u969c\u7ea6\u675f\u548c\u51e0\u4f55\u7ed3\u6784\uff1b3) \u5f15\u5165\u7c7b\u4f3c\u652f\u6301\u5411\u91cf\u673a\u7684\u8fb9\u754c\u89e3\u91ca\u548c'\u652f\u6301token'\u6982\u5ff5\uff1b4) \u5c06LLM\u5efa\u6a21\u4e3atoken\u7a7a\u95f4\u5e42\u96c6\u4e0a\u7684\u968f\u673a\u8fc7\u7a0b\uff1b5) \u63d0\u51fa\u8d1d\u53f6\u65af\u6846\u67b6\u548cMAP\u4f30\u8ba1\u76ee\u6807\uff0c\u5728\u4ea4\u53c9\u71b5\u635f\u5931\u4e2d\u6dfb\u52a0\u5e73\u6ed1\u5bf9\u6570\u5c4f\u969c\u60e9\u7f5a\u9879\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a1) \u63ed\u793a\u4e86\u81ea\u6ce8\u610f\u529b\u53c2\u6570\u7684\u5c4f\u969c\u7ea6\u675f\u8bf1\u5bfc\u4e86token\u7a7a\u95f4\u7684\u7ed3\u6784\u5316\u51e0\u4f55\uff1b2) \u63d0\u51fa\u4e86\u7c7b\u4f3c\u652f\u6301\u5411\u91cf\u673a\u7684\u8fb9\u754c\u89e3\u91ca\u548c\u652f\u6301token\u6982\u5ff5\uff1b3) \u5efa\u7acb\u4e86LLM\u4f5c\u4e3a\u968f\u673a\u8fc7\u7a0b\u7684\u6982\u7387\u6846\u67b6\uff1b4) \u63d0\u51fa\u7684\u65b9\u6cd5\u53ea\u9700\u6700\u5c0f\u4fee\u6539\u6807\u51c6LLM\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\uff0c\u5728\u4e0d\u727a\u7272\u6837\u672c\u5916\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u66f4\u7a33\u5065\u7684\u6a21\u578b\uff0c\u4e14\u5b9e\u9645\u5b9e\u65bd\u7b80\u5355\u76f4\u63a5\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\uff0c\u901a\u8fc7\u5c06\u81ea\u6ce8\u610f\u529btransformer\u91cd\u65b0\u89e3\u91ca\u4e3a\u6982\u7387\u6846\u67b6\uff0c\u53ef\u4ee5\u63ed\u793a\u5176\u6df1\u5c42\u7ed3\u6784\u548c\u7ea6\u675f\u7279\u6027\u3002\u63d0\u51fa\u7684\u8d1d\u53f6\u65af\u6846\u67b6\u548cMAP\u4f30\u8ba1\u65b9\u6cd5\u4e3a\u5e8f\u5217\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u4e25\u8c28\u7684\u7406\u8bba\u57fa\u7840\uff0c\u800c\u7b80\u5355\u7684\u5e73\u6ed1\u5bf9\u6570\u5c4f\u969c\u60e9\u7f5a\u9879\u6dfb\u52a0\u5c31\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u7406\u89e3LLM\u7684\u673a\u5236\u548c\u89e3\u7801\u52a8\u529b\u5b66\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c6\u89d2\u548c\u5b9e\u7528\u6539\u8fdb\u65b9\u6848\u3002"}}
{"id": "2602.22277", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.22277", "abs": "https://arxiv.org/abs/2602.22277", "authors": ["Abdul Karim Gizzini", "Yahia Medjahdi"], "title": "X-REFINE: XAI-based RElevance input-Filtering and archItecture fiNe-tuning for channel Estimation", "comment": "This paper has been accepted for publication in the IEEE Transactions on Vehicular Technology (TVT) as a correspondence paper", "summary": "AI-native architectures are vital for 6G wireless communications. The black-box nature and high complexity of deep learning models employed in critical applications, such as channel estimation, limit their practical deployment. While perturbation-based XAI solutions offer input filtering, they often neglect internal structural optimization. We propose X-REFINE, an XAI-based framework for joint input-filtering and architecture fine-tuning. By utilizing a decomposition-based, sign-stabilized LRP epsilon rule, X-REFINE backpropagates predictions to derive high-resolution relevance scores for both subcarriers and hidden neurons. This enables a holistic optimization that identifies the most faithful model components. Simulation results demonstrate that X-REFINE achieves a superior interpretability-performance-complexity trade-off, significantly reducing computational complexity while maintaining robust bit error rate (BER) performance across different scenarios.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.22288", "categories": ["cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.22288", "abs": "https://arxiv.org/abs/2602.22288", "authors": ["Vin\u00edcius P. Chagas", "Luiz H. T. Viana", "Mac M. da S. Carlos", "Jo\u00e3o P. V. Madeiro", "Roberto C. Pedrosa", "Thiago Alves Rocha", "Carlos H. L. Cavalcante"], "title": "Reliable XAI Explanations in Sudden Cardiac Death Prediction for Chagas Cardiomyopathy", "comment": "Preprint. For the final published version, see the DOI below", "summary": "Sudden cardiac death (SCD) is unpredictable, and its prediction in Chagas cardiomyopathy (CC) remains a significant challenge, especially in patients not classified as high risk. While AI and machine learning models improve risk stratification, their adoption is hindered by a lack of transparency, as they are often perceived as \\textit{black boxes} with unclear decision-making processes. Some approaches apply heuristic explanations without correctness guarantees, leading to mistakes in the decision-making process. To address this, we apply a logic-based explainability method with correctness guarantees to the problem of SCD prediction in CC. This explainability method, applied to an AI classifier with over 95\\% accuracy and recall, demonstrated strong predictive performance and 100\\% explanation fidelity. When compared to state-of-the-art heuristic methods, it showed superior consistency and robustness. This approach enhances clinical trust, facilitates the integration of AI-driven tools into practice, and promotes large-scale deployment, particularly in endemic regions where it is most needed.", "AI": {"tldr": "\u5e94\u7528\u903b\u8f91\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u4e8e\u6070\u52a0\u65af\u5fc3\u808c\u75c5\u7684\u731d\u6b7b\u9884\u6d4b\uff0c\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u63d0\u4f9b\u6b63\u786e\u6027\u4fdd\u969c\u7684\u89e3\u91ca", "motivation": "\u6070\u52a0\u65af\u5fc3\u808c\u75c5\u60a3\u8005\u7684\u731d\u6b7b\u9884\u6d4b\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709AI\u6a21\u578b\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u88ab\u89c6\u4e3a\u9ed1\u7bb1\uff0c\u7f3a\u4e4f\u51b3\u7b56\u8fc7\u7a0b\u53ef\u89e3\u91ca\u6027\uff0c\u4e14\u542f\u53d1\u5f0f\u89e3\u91ca\u65b9\u6cd5\u65e0\u6cd5\u4fdd\u8bc1\u6b63\u786e\u6027", "method": "\u5e94\u7528\u5e26\u6709\u6b63\u786e\u6027\u4fdd\u8bc1\u7684\u903b\u8f91\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u5e94\u7528\u4e8e\u51c6\u786e\u7387\u8d85\u8fc795%\u7684AI\u5206\u7c7b\u5668\uff0c\u786e\u4fdd\u89e3\u91ca\u4e0e\u6a21\u578b\u51b3\u7b56\u5b8c\u5168\u4e00\u81f4", "result": "\u65b9\u6cd5\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u9884\u6d4b\u6027\u80fd\uff08100%\u89e3\u91ca\u4fdd\u771f\u5ea6\uff09\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u548c\u4e00\u81f4\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7684\u89e3\u91ca\u589e\u5f3a\u4e86\u4e34\u5e8a\u4fe1\u4efb\u5ea6\uff0c\u6709\u52a9\u4e8eAI\u5de5\u5177\u5728\u5b9e\u9645\u533b\u7597\u4e2d\u7684\u96c6\u6210\u548c\u5927\u89c4\u6a21\u90e8\u7f72\uff0c\u7279\u522b\u662f\u5728\u6d41\u884c\u5730\u533a"}}
{"id": "2602.22777", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.22777", "abs": "https://arxiv.org/abs/2602.22777", "authors": ["Mingming Zhang", "Pengfei Shi", "Zhiqing Xiao", "Feng Zhao", "Guandong Sun", "Yulin Kang", "Ruizhe Gao", "Ningtao Wang", "Xing Fu", "Weiqiang Wang", "Junbo Zhao"], "title": "KMLP: A Scalable Hybrid Architecture for Web-Scale Tabular Data Modeling", "comment": "Accepted by THE ACM WEB CONFERENCE 2026", "summary": "Predictive modeling on web-scale tabular data with billions of instances and hundreds of heterogeneous numerical features faces significant scalability challenges. These features exhibit anisotropy, heavy-tailed distributions, and non-stationarity, creating bottlenecks for models like Gradient Boosting Decision Trees and requiring laborious manual feature engineering. We introduce KMLP, a hybrid deep architecture integrating a shallow Kolmogorov-Arnold Network (KAN) front-end with a Gated Multilayer Perceptron (gMLP) backbone. The KAN front-end uses learnable activation functions to automatically model complex non-linear transformations for each feature, while the gMLP backbone captures high-order interactions. Experiments on public benchmarks and an industrial dataset with billions of samples show KMLP achieves state-of-the-art performance, with advantages over baselines like GBDTs increasing at larger scales, validating KMLP as a scalable deep learning paradigm for large-scale web tabular data.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
