<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 8]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Entropy-Controlled Flow Matching](https://arxiv.org/abs/2602.22265)
*Chika Maduabuchi*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Modern vision generators transport a base distribution to data through time-indexed measures, implemented as deterministic flows (ODEs) or stochastic diffusions (SDEs). Despite strong empirical performance, standard flow-matching objectives do not directly control the information geometry of the trajectory, allowing low-entropy bottlenecks that can transiently deplete semantic modes. We propose Entropy-Controlled Flow Matching (ECFM): a constrained variational principle over continuity-equation paths enforcing a global entropy-rate budget d/dt H(mu_t) >= -lambda. ECFM is a convex optimization in Wasserstein space with a KKT/Pontryagin system, and admits a stochastic-control representation equivalent to a Schrodinger bridge with an explicit entropy multiplier. In the pure transport regime, ECFM recovers entropic OT geodesics and Gamma-converges to classical OT as lambda -> 0. We further obtain certificate-style mode-coverage and density-floor guarantees with Lipschitz stability, and construct near-optimal collapse counterexamples for unconstrained flow matching.

</details>


### [2] [Data-Driven Supervision of a Thermal-Hydraulic Process Towards a Physics-Based Digital Twin](https://arxiv.org/abs/2602.22267)
*Osimone Imhogiemhe,Yoann Jus,Hubert Lejeune,Saïd Moussaoui*

Main category: cs.LG

TL;DR: 该论文开发了基于数字孪体框架的故障检测与诊断算法，结合数值仿真和机器学习方法，用于热工水力过程监控中的参数变化检测与在线估计。


<details>
  <summary>Details</summary>
Motivation: 工业生产过程实时监控是多个行业面临的共同挑战，需要对过程组件进行监控和预测性维护，以确保安全、持续生产并保持高效率。数字孪体概念为设计高效的系统监控数值工具提供了可能。

Method: 基于热工水力过程的数值仿真，结合机器学习方法，提出了用于过程参数变化检测和在线估计的不同模块。开发了专门的故障检测与诊断算法，并在特定测试场景下进行了验证。

Result: 在单一参数变化的测试场景中，算法在参数变化定位和数值更新方面表现出良好的准确性。

Conclusion: 数字孪体框架为工业过程监控提供了有效的解决方案，所提出的故障检测与诊断算法能够准确检测和定位系统参数变化，验证了数字孪体在过程监控应用中的可行性。

Abstract: The real-time supervision of production processes is a common challenge across several industries. It targets process component monitoring and its predictive maintenance in order to ensure safety, uninterrupted production and maintain high efficiency level. The rise of advanced tools for the simulation of physical systems in addition to data-driven machine learning models offers the possibility to design numerical tools dedicated to efficient system monitoring. In that respect, the digital twin concept presents an adequate framework that proffers solution to these challenges. The main purpose of this paper is to develop such a digital twin dedicated to fault detection and diagnosis in the context of a thermal-hydraulic process supervision. Based on a numerical simulation of the system, in addition to machine learning methods, we propose different modules dedicated to process parameter change detection and their on-line estimation. The proposed fault detection and diagnosis algorithm is validated on a specific test scenario, with single one-off parameter change occurrences in the system. The numerical results show good accuracy in terms of parameter variation localization and the update of their values.

</details>


### [3] [AutoQRA: Joint Optimization of Mixed-Precision Quantization and Low-rank Adapters for Efficient LLM Fine-Tuning](https://arxiv.org/abs/2602.22268)
*Changhai Zhou,Shiyang Zhang,Yuhua Zhou,Qian Qiao,Jun Gao,Cheng Jin,Kaizhou Qin,Weizhong Zhang*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantization followed by parameter-efficient fine-tuning has emerged as a promising paradigm for downstream adaptation under tight GPU memory constraints. However, this sequential pipeline fails to leverage the intricate interaction between quantization bit-width and LoRA rank. Specifically, a carefully optimized quantization allocation with low quantization error does not always translate to strong fine-tuning performance, and different bit-width and rank configurations can lead to significantly varying outcomes under the same memory budget. To address this limitation, we propose AutoQRA, a joint optimization framework that simultaneously optimizes the bit-width and LoRA rank configuration for each layer during the mixed quantized fine-tuning process. To tackle the challenges posed by the large discrete search space and the high evaluation cost associated with frequent fine-tuning iterations, AutoQRA decomposes the optimization process into two stages. First, it first conducts a global multi-fidelity evolutionary search, where the initial population is warm-started by injecting layer-wise importance priors. This stage employs specific operators and a performance model to efficiently screen candidate configurations. Second, trust-region Bayesian optimization is applied to locally refine promising regions of the search space and identify optimal configurations under the given memory budget. This approach enables active compensation for quantization noise in specific layers during training. Experiments show that AutoQRA achieves performance close to full-precision fine-tuning with a memory footprint comparable to uniform 4-bit methods.

</details>


### [4] [CQSA: Byzantine-robust Clustered Quantum Secure Aggregation in Federated Learning](https://arxiv.org/abs/2602.22269)
*Arnab Nath,Harsh Kasyap*

Main category: cs.LG

TL;DR: 提出了Clustered Quantum Secure Aggregation（CQSA）——一种模块化量子安全聚合框架，通过将客户分成小集群使用高保真度的低量子比特GHZ态进行本地量子聚合，解决了现有全局量子安全聚合方案在大规模部署时的保真度下降和拜占庭客户端检测问题。


<details>
  <summary>Details</summary>
Motivation: 现有的量子安全聚合协议依赖于所有参与客户共享的单个全局GHZ态，这存在两个基本挑战：随着客户数量的增加，大规模GHZ态的保真度迅速下降；全局聚合防止了拜占庭客户端的检测。需要一种能够协调近期量子硬件的物理约束与联邦学习中对拜占庭鲁棒性需求的新方案。

Method: 提出CQSA框架：1. 将客户随机分成小集群；2. 每个集群使用高保真度、低量子比特的GHZ态进行本地量子聚合；3. 服务器分析集群级聚合之间的统计关系（使用余弦相似度和欧氏距离等统计度量）来识别恶意贡献。

Result: 理论分析和去极化噪声下的模拟表明，CQSA确保了稳定的模型收敛，并在状态保真度上优于全局QSA。

Conclusion: CQSA成功地协调了近期量子硬件的物理约束与联邦学习中对于拜占庭鲁棒性的需求，提供了一种可行的量子辅助联邦学习安全聚合方案。

Abstract: Federated Learning (FL) enables collaborative model training without sharing raw data. However, shared local model updates remain vulnerable to inference and poisoning attacks. Secure aggregation schemes have been proposed to mitigate these attacks. In this work, we aim to understand how these techniques are implemented in quantum-assisted FL. Quantum Secure Aggregation (QSA) has been proposed, offering information-theoretic privacy by encoding client updates into the global phase of multipartite entangled states. Existing QSA protocols, however, rely on a single global Greenberger-Horne-Zeilinger (GHZ) state shared among all participating clients. This design poses fundamental challenges: fidelity of large-scale GHZ states deteriorates rapidly with the increasing number of clients; and (ii) the global aggregation prevents the detection of Byzantine clients. We propose Clustered Quantum Secure Aggregation (CQSA), a modular aggregation framework that reconciles the physical constraints of near-term quantum hardware along with the need for Byzantine-robustness in FL. CQSA randomly partitions the clients into small clusters, each performing local quantum aggregation using high-fidelity, low-qubit GHZ states. The server analyzes statistical relationships between cluster-level aggregates employing common statistical measures such as cosine similarity and Euclidean distance to identify malicious contributions. Through theoretical analysis and simulations under depolarizing noise, we demonstrate that CQSA ensures stable model convergence, achieves superior state fidelity over global QSA.

</details>


### [5] [Support Tokens, Stability Margins, and a New Foundation for Robust LLMs](https://arxiv.org/abs/2602.22271)
*Deepak Agarwal,Dhyey Dharmendrakumar Mavani,Suyash Gupta,Karthik Sethuraman,Tejas Dharamsi*

Main category: cs.LG

TL;DR: 该论文将因果自注意力transformer重新解释为概率框架，揭示了自注意力参数存在屏障约束，这诱导了token空间的高度结构化几何形状，并提出了基于支持向量机原理的'支持token'概念。研究还展示了LLM可被解释为token空间幂集上的随机过程，提出了贝叶斯框架和MAP估计目标，只需在标准LLM训练中添加平滑对数屏障惩罚即可实现更稳健的模型。


<details>
  <summary>Details</summary>
Motivation: 动机是重新解释现代基础模型的核心组件——因果自注意力transformer，将其置于类似概率PCA的框架中，以揭示其底层结构和理论洞察。这种重新表述旨在提供对LLM解码动力学更深入的理解，并建立更坚实的理论基础。

Method: 方法包括：1) 将因果自注意力重新解释为概率框架；2) 揭示自注意力参数中的屏障约束和几何结构；3) 引入类似支持向量机的边界解释和'支持token'概念；4) 将LLM建模为token空间幂集上的随机过程；5) 提出贝叶斯框架和MAP估计目标，在交叉熵损失中添加平滑对数屏障惩罚项。

Result: 结果显示：1) 揭示了自注意力参数的屏障约束诱导了token空间的结构化几何；2) 提出了类似支持向量机的边界解释和支持token概念；3) 建立了LLM作为随机过程的概率框架；4) 提出的方法只需最小修改标准LLM训练即可实现，在不牺牲样本外准确性的同时提供更稳健的模型，且实际实施简单直接。

Conclusion: 结论表明，通过将自注意力transformer重新解释为概率框架，可以揭示其深层结构和约束特性。提出的贝叶斯框架和MAP估计方法为序列建模提供了更严谨的理论基础，而简单的平滑对数屏障惩罚项添加就能有效提升模型的鲁棒性。这项工作为理解LLM的机制和解码动力学提供了新的理论视角和实用改进方案。

Abstract: Self-attention is usually described as a flexible, content-adaptive way to mix a token with information from its past. We re-interpret causal self-attention transformers, the backbone of modern foundation models, within a probabilistic framework, much like how classical PCA is extended to probabilistic PCA. However, this re-formulation reveals a surprising and deeper structural insight: due to a change-of-variables phenomenon, a barrier constraint emerges on the self-attention parameters. This induces a highly structured geometry on the token space, providing theoretical insights into the dynamics of LLM decoding. This reveals a boundary where attention becomes ill-conditioned, leading to a margin interpretation similar to classical support vector machines. Just like support vectors, this naturally gives rise to the concept of support tokens.
  Furthermore, we show that LLMs can be interpreted as a stochastic process over the power set of the token space, providing a rigorous probabilistic framework for sequence modeling. We propose a Bayesian framework and derive a MAP estimation objective that requires only a minimal modification to standard LLM training: the addition of a smooth log-barrier penalty to the usual cross-entropy loss. We demonstrate that this provides more robust models without sacrificing out-of-sample accuracy and that it is straightforward to incorporate in practice.

</details>


### [6] [X-REFINE: XAI-based RElevance input-Filtering and archItecture fiNe-tuning for channel Estimation](https://arxiv.org/abs/2602.22277)
*Abdul Karim Gizzini,Yahia Medjahdi*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: AI-native architectures are vital for 6G wireless communications. The black-box nature and high complexity of deep learning models employed in critical applications, such as channel estimation, limit their practical deployment. While perturbation-based XAI solutions offer input filtering, they often neglect internal structural optimization. We propose X-REFINE, an XAI-based framework for joint input-filtering and architecture fine-tuning. By utilizing a decomposition-based, sign-stabilized LRP epsilon rule, X-REFINE backpropagates predictions to derive high-resolution relevance scores for both subcarriers and hidden neurons. This enables a holistic optimization that identifies the most faithful model components. Simulation results demonstrate that X-REFINE achieves a superior interpretability-performance-complexity trade-off, significantly reducing computational complexity while maintaining robust bit error rate (BER) performance across different scenarios.

</details>


### [7] [Reliable XAI Explanations in Sudden Cardiac Death Prediction for Chagas Cardiomyopathy](https://arxiv.org/abs/2602.22288)
*Vinícius P. Chagas,Luiz H. T. Viana,Mac M. da S. Carlos,João P. V. Madeiro,Roberto C. Pedrosa,Thiago Alves Rocha,Carlos H. L. Cavalcante*

Main category: cs.LG

TL;DR: 应用逻辑可解释性方法于恰加斯心肌病的猝死预测，在保持高准确率的同时提供正确性保障的解释


<details>
  <summary>Details</summary>
Motivation: 恰加斯心肌病患者的猝死预测具有挑战性，现有AI模型缺乏透明度，被视为黑箱，缺乏决策过程可解释性，且启发式解释方法无法保证正确性

Method: 应用带有正确性保证的逻辑可解释性方法，应用于准确率超过95%的AI分类器，确保解释与模型决策完全一致

Result: 方法展现出强大的预测性能（100%解释保真度），与最先进的启发式方法相比具有更好的鲁棒性和一致性

Conclusion: 该方法通过提供可验证的解释增强了临床信任度，有助于AI工具在实际医疗中的集成和大规模部署，特别是在流行地区

Abstract: Sudden cardiac death (SCD) is unpredictable, and its prediction in Chagas cardiomyopathy (CC) remains a significant challenge, especially in patients not classified as high risk. While AI and machine learning models improve risk stratification, their adoption is hindered by a lack of transparency, as they are often perceived as \textit{black boxes} with unclear decision-making processes. Some approaches apply heuristic explanations without correctness guarantees, leading to mistakes in the decision-making process. To address this, we apply a logic-based explainability method with correctness guarantees to the problem of SCD prediction in CC. This explainability method, applied to an AI classifier with over 95\% accuracy and recall, demonstrated strong predictive performance and 100\% explanation fidelity. When compared to state-of-the-art heuristic methods, it showed superior consistency and robustness. This approach enhances clinical trust, facilitates the integration of AI-driven tools into practice, and promotes large-scale deployment, particularly in endemic regions where it is most needed.

</details>


### [8] [KMLP: A Scalable Hybrid Architecture for Web-Scale Tabular Data Modeling](https://arxiv.org/abs/2602.22777)
*Mingming Zhang,Pengfei Shi,Zhiqing Xiao,Feng Zhao,Guandong Sun,Yulin Kang,Ruizhe Gao,Ningtao Wang,Xing Fu,Weiqiang Wang,Junbo Zhao*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Predictive modeling on web-scale tabular data with billions of instances and hundreds of heterogeneous numerical features faces significant scalability challenges. These features exhibit anisotropy, heavy-tailed distributions, and non-stationarity, creating bottlenecks for models like Gradient Boosting Decision Trees and requiring laborious manual feature engineering. We introduce KMLP, a hybrid deep architecture integrating a shallow Kolmogorov-Arnold Network (KAN) front-end with a Gated Multilayer Perceptron (gMLP) backbone. The KAN front-end uses learnable activation functions to automatically model complex non-linear transformations for each feature, while the gMLP backbone captures high-order interactions. Experiments on public benchmarks and an industrial dataset with billions of samples show KMLP achieves state-of-the-art performance, with advantages over baselines like GBDTs increasing at larger scales, validating KMLP as a scalable deep learning paradigm for large-scale web tabular data.

</details>
